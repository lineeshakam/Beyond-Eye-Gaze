{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7c63d9",
   "metadata": {},
   "source": [
    "# EMG Encoder - Temporal CNN for Phoneme Prediction\n",
    "Mapping MyoWare muscle sensor sequences to phonemes using a Temporal Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5ec8c",
   "metadata": {},
   "source": [
    "## 1. Phoneme Mapping & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71024a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phoneme mapping and muscle sensor configuration\n",
    "PHONEMES = [\n",
    "    'a', 'e', 'i', 'o', 'u',           # Vowels\n",
    "    'p', 'b', 'm', 'f', 'v',           # Labial consonants (lips)\n",
    "    't', 'd', 'n', 'l',                # Alveolar consonants (tongue tip)\n",
    "    'k', 'g', 'ng',                    # Velar consonants (tongue back)\n",
    "    's', 'z', 'sh', 'zh',              # Sibilants (tongue/teeth)\n",
    "    'ch', 'j', 'th', 'dh',             # Other consonants\n",
    "    'r', 'y', 'w'                      # Approximants\n",
    "]\n",
    "\n",
    "# MyoWare sensor locations mapping to phoneme groups\n",
    "MUSCLE_SENSORS = {\n",
    "    'biceps': 0,          # Arm movement (general movements, 'r', 'w')\n",
    "    'forearm': 1,         # Forearm (precise movements)\n",
    "    'masseter': 2,        # Jaw/chewing muscle (labial consonants: p, b, m, f, v)\n",
    "    'orbicularis_oris': 3, # Lips (vowels, labial consonants)\n",
    "    'temporalis': 4,      # Temple/jaw (velar consonants: k, g)\n",
    "    'tongue': 5,          # Tongue (sibilants, alveolars)\n",
    "    'larynx': 6,          # Throat (voicing, fricatives)\n",
    "}\n",
    "\n",
    "NUM_SENSORS = len(MUSCLE_SENSORS)\n",
    "NUM_PHONEMES = len(PHONEMES)\n",
    "\n",
    "print(f\"Number of EMG Sensors: {NUM_SENSORS}\")\n",
    "print(f\"Number of Phonemes: {NUM_PHONEMES}\")\n",
    "print(f\"Phoneme Mapping: {PHONEMES}\")\n",
    "print(f\"Muscle Sensors: {list(MUSCLE_SENSORS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c454d7d8",
   "metadata": {},
   "source": [
    "## 2. EMG Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TRUE DATASET CLASS\n",
    "\n",
    "# COMMENTED OUT - Uncomment this cell to load real MyoWare sensor data\n",
    "\"\"\"\n",
    "# Load real EMG data from disk\n",
    "def load_real_emg_data(data_dir='./data/processed'):\n",
    "    '''\n",
    "    Load real EMG sequences and labels from preprocessed data files\n",
    "    Expected files:\n",
    "    - data/processed/train_sequences.npy: shape (num_samples, num_sensors, seq_length)\n",
    "    - data/processed/train_labels.npy: shape (num_samples,)\n",
    "    - data/processed/test_sequences.npy\n",
    "    - data/processed/test_labels.npy\n",
    "    '''\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"Data directory not found: {data_dir}\")\n",
    "    \n",
    "    # Load training data\n",
    "    train_sequences = np.load(data_path / 'train_sequences.npy')\n",
    "    train_labels = np.load(data_path / 'train_labels.npy')\n",
    "    \n",
    "    # Load test data\n",
    "    test_sequences = np.load(data_path / 'test_sequences.npy')\n",
    "    test_labels = np.load(data_path / 'test_labels.npy')\n",
    "    \n",
    "    print(f\"Loaded {len(train_sequences)} training sequences\")\n",
    "    print(f\"Loaded {len(test_sequences)} test sequences\")\n",
    "    \n",
    "    return train_sequences, train_labels, test_sequences, test_labels\n",
    "\n",
    "# Uncomment to use real data instead of synthetic:\n",
    "# train_sequences, train_labels, test_sequences, test_labels = load_real_emg_data()\n",
    "# sequences = np.concatenate([train_sequences, test_sequences])\n",
    "# labels = np.concatenate([train_labels, test_labels])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de931e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMGDataset(Dataset):\n",
    "    \"\"\"\n",
    "    EMG Dataset for phoneme prediction\n",
    "    Each sample is a sequence of EMG readings mapped to a phoneme\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences, labels, seq_length=100, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sequences: List of EMG signal sequences (num_samples, num_sensors, time_steps)\n",
    "            labels: List of phoneme indices\n",
    "            seq_length: Fixed sequence length\n",
    "            transform: Optional preprocessing function\n",
    "        \"\"\"\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.seq_length = seq_length\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get sequence and pad/truncate to fixed length\n",
    "        seq = self.sequences[idx]\n",
    "        \n",
    "        # Ensure correct shape (num_sensors, time_steps)\n",
    "        if seq.shape[0] != NUM_SENSORS:\n",
    "            seq = seq.T if seq.shape[1] == NUM_SENSORS else seq\n",
    "        \n",
    "        # Pad or truncate to seq_length\n",
    "        if seq.shape[1] < self.seq_length:\n",
    "            # Pad with zeros\n",
    "            padding = np.zeros((NUM_SENSORS, self.seq_length - seq.shape[1]))\n",
    "            seq = np.concatenate([seq, padding], axis=1)\n",
    "        else:\n",
    "            # Truncate\n",
    "            seq = seq[:, :self.seq_length]\n",
    "        \n",
    "        if self.transform:\n",
    "            seq = self.transform(seq)\n",
    "        \n",
    "        return torch.FloatTensor(seq), torch.LongTensor([self.labels[idx]])[0]\n",
    "\n",
    "\n",
    "def generate_synthetic_emg_data(num_samples=200, seq_length=100, num_sensors=NUM_SENSORS):\n",
    "    \"\"\"\n",
    "    Generate synthetic EMG data for testing\n",
    "    In practice, this would come from MyoWare sensors\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Random phoneme\n",
    "        phoneme_idx = np.random.randint(0, NUM_PHONEMES)\n",
    "        label = phoneme_idx\n",
    "        \n",
    "        # Generate EMG-like signal\n",
    "        # Different phonemes have different muscle activation patterns\n",
    "        seq = np.random.normal(0, 0.1, (num_sensors, seq_length))\n",
    "        \n",
    "        # Add muscle-specific patterns for phoneme\n",
    "        if phoneme_idx in [0, 1, 2, 3, 4]:  # Vowels\n",
    "            seq[3] += np.random.normal(0.5, 0.1, seq_length)  # orbicularis_oris\n",
    "        \n",
    "        if phoneme_idx in [5, 6, 7, 8, 9]:  # Labial consonants (p, b, m, f, v)\n",
    "            seq[2] += np.random.normal(0.7, 0.1, seq_length)  # masseter\n",
    "            seq[3] += np.random.normal(0.6, 0.1, seq_length)  # orbicularis_oris\n",
    "        \n",
    "        if phoneme_idx in [10, 11, 12, 13]:  # Alveolar consonants\n",
    "            seq[5] += np.random.normal(0.6, 0.1, seq_length)  # tongue\n",
    "        \n",
    "        if phoneme_idx in [14, 15, 16]:  # Velar consonants\n",
    "            seq[4] += np.random.normal(0.7, 0.1, seq_length)  # temporalis\n",
    "            seq[5] += np.random.normal(0.5, 0.1, seq_length)  # tongue\n",
    "        \n",
    "        # Ensure positive (EMG is rectified)\n",
    "        seq = np.abs(seq)\n",
    "        \n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return sequences, labels\n",
    "\n",
    "\n",
    "# Generate synthetic data\n",
    "print(\"Generating synthetic EMG data...\")\n",
    "sequences, labels = generate_synthetic_emg_data(num_samples=400)\n",
    "print(f\"Generated {len(sequences)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a6ed6",
   "metadata": {},
   "source": [
    "## 3. Temporal CNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b75dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal Convolutional Neural Network for EMG sequence classification\n",
    "    Uses dilated convolutions to capture long-range temporal dependencies\n",
    "    \"\"\"\n",
    "    def __init__(self, num_sensors, num_phonemes, num_channels=64, kernel_size=3, dropout=0.3):\n",
    "        super(TemporalCNN, self).__init__()\n",
    "        \n",
    "        self.num_sensors = num_sensors\n",
    "        self.num_phonemes = num_phonemes\n",
    "        \n",
    "        # Temporal convolution blocks with increasing dilation\n",
    "        self.conv1 = nn.Conv1d(num_sensors, num_channels, kernel_size, \n",
    "                              padding=kernel_size//2, dilation=1)\n",
    "        self.bn1 = nn.BatchNorm1d(num_channels)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(num_channels, num_channels * 2, kernel_size,\n",
    "                              padding=kernel_size//2, dilation=2)\n",
    "        self.bn2 = nn.BatchNorm1d(num_channels * 2)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(num_channels * 2, num_channels * 4, kernel_size,\n",
    "                              padding=kernel_size//2, dilation=4)\n",
    "        self.bn3 = nn.BatchNorm1d(num_channels * 4)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Global average pooling will be applied\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(num_channels * 4, num_channels * 2)\n",
    "        self.dropout_fc = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(num_channels * 2, num_phonemes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_sensors, seq_length)\n",
    "        \n",
    "        # Conv block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Conv block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Conv block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = torch.mean(x, dim=2)  # (batch_size, num_channels*4)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = TemporalCNN(\n",
    "    num_sensors=NUM_SENSORS,\n",
    "    num_phonemes=NUM_PHONEMES,\n",
    "    num_channels=64,\n",
    "    kernel_size=3,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model architecture:\\n{model}\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9beedb",
   "metadata": {},
   "source": [
    "## 4. Data Preparation & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Normalize EMG signals\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Flatten sequences for scaling\n",
    "sequences_flat = np.concatenate([s.flatten() for s in sequences]).reshape(-1, 1)\n",
    "scaler.fit(sequences_flat)\n",
    "\n",
    "# Apply scaling to sequences\n",
    "sequences_normalized = []\n",
    "for seq in sequences:\n",
    "    seq_flat = seq.reshape(-1, 1)\n",
    "    seq_scaled = scaler.transform(seq_flat).reshape(seq.shape)\n",
    "    sequences_normalized.append(seq_scaled)\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(\n",
    "    sequences_normalized, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_sequences)}\")\n",
    "print(f\"Test samples: {len(test_sequences)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EMGDataset(train_sequences, train_labels, seq_length=100)\n",
    "test_dataset = EMGDataset(test_sequences, test_labels, seq_length=100)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"DataLoader created with batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3b404",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f3f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "best_accuracy = 0\n",
    "best_model_state = None\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_emg, batch_labels in train_loader:\n",
    "        batch_emg = batch_emg.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_emg)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_emg, batch_labels in test_loader:\n",
    "            batch_emg = batch_emg.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_emg)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_labels.size(0)\n",
    "            correct += (predicted == batch_labels).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracy = correct / total\n",
    "    test_accuracies.append(accuracy)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_state = model.state_dict().copy()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Test Loss: {test_loss:.4f} | Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Training completed! Best Test Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_model_state)\n",
    "print(\"Loaded best model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f136e0d0",
   "metadata": {},
   "source": [
    "## 6. Visualization & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc095b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "ax1.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "ax1.plot(test_losses, label='Test Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Test Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(test_accuracies, label='Test Accuracy', linewidth=2, color='green')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Test Accuracy Over Epochs')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_results.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best test accuracy achieved: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3965a",
   "metadata": {},
   "source": [
    "## 7. Inference & Real-time Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4eba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMGEncoder:\n",
    "    \"\"\"\n",
    "    Real-time EMG to Phoneme encoder\n",
    "    Use this class for inference with live MyoWare sensor data\n",
    "    \"\"\"\n",
    "    def __init__(self, model, scaler, device='cpu'):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.device = device\n",
    "        self.model.eval()\n",
    "        \n",
    "    def predict_phoneme(self, emg_sequence):\n",
    "        \"\"\"\n",
    "        Predict phoneme from EMG sequence\n",
    "        \n",
    "        Args:\n",
    "            emg_sequence: numpy array of shape (num_sensors, seq_length) or (num_sensors,)\n",
    "        \n",
    "        Returns:\n",
    "            phoneme: predicted phoneme\n",
    "            confidence: confidence score (0-1)\n",
    "            probabilities: softmax probabilities for all phonemes\n",
    "        \"\"\"\n",
    "        # Ensure correct shape\n",
    "        if emg_sequence.ndim == 1:\n",
    "            # Single timestep, repeat it\n",
    "            emg_sequence = np.repeat(emg_sequence[:, np.newaxis], 100, axis=1)\n",
    "        \n",
    "        if emg_sequence.shape[0] != NUM_SENSORS:\n",
    "            emg_sequence = emg_sequence.T\n",
    "        \n",
    "        # Pad or truncate\n",
    "        if emg_sequence.shape[1] < 100:\n",
    "            padding = np.zeros((NUM_SENSORS, 100 - emg_sequence.shape[1]))\n",
    "            emg_sequence = np.concatenate([emg_sequence, padding], axis=1)\n",
    "        else:\n",
    "            emg_sequence = emg_sequence[:, :100]\n",
    "        \n",
    "        # Normalize\n",
    "        emg_flat = emg_sequence.reshape(-1, 1)\n",
    "        emg_scaled = self.scaler.transform(emg_flat).reshape(emg_sequence.shape)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        emg_tensor = torch.FloatTensor(emg_scaled).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(emg_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1)[0].cpu().numpy()\n",
    "            predicted_idx = np.argmax(probabilities)\n",
    "        \n",
    "        phoneme = PHONEMES[predicted_idx]\n",
    "        confidence = float(probabilities[predicted_idx])\n",
    "        \n",
    "        return phoneme, confidence, probabilities\n",
    "    \n",
    "    def predict_sequence(self, emg_sequences):\n",
    "        \"\"\"\n",
    "        Predict sequence of phonemes from multiple EMG sequences\n",
    "        \n",
    "        Args:\n",
    "            emg_sequences: list of EMG arrays\n",
    "        \n",
    "        Returns:\n",
    "            phoneme_sequence: list of predicted phonemes\n",
    "            confidence_scores: list of confidence scores\n",
    "        \"\"\"\n",
    "        phoneme_sequence = []\n",
    "        confidence_scores = []\n",
    "        \n",
    "        for seq in emg_sequences:\n",
    "            phoneme, confidence, _ = self.predict_phoneme(seq)\n",
    "            phoneme_sequence.append(phoneme)\n",
    "            confidence_scores.append(confidence)\n",
    "        \n",
    "        return phoneme_sequence, confidence_scores\n",
    "\n",
    "\n",
    "# Initialize encoder\n",
    "encoder = EMGEncoder(model, scaler, device=device)\n",
    "\n",
    "# Test with random samples\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing Phoneme Prediction\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i in range(5):\n",
    "    test_emg = test_sequences[i]\n",
    "    true_label = PHONEMES[test_labels[i]]\n",
    "    \n",
    "    predicted_phoneme, confidence, probs = encoder.predict_phoneme(test_emg)\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  True phoneme: {true_label}\")\n",
    "    print(f\"  Predicted phoneme: {predicted_phoneme}\")\n",
    "    print(f\"  Confidence: {confidence:.4f}\")\n",
    "    print(f\"  Match: {'✓' if true_label == predicted_phoneme else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2544f548",
   "metadata": {},
   "source": [
    "## 8. Model Persistence & Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2568f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_save_path = 'emg_encoder_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'num_sensors': NUM_SENSORS,\n",
    "        'num_phonemes': NUM_PHONEMES,\n",
    "        'num_channels': 64,\n",
    "        'kernel_size': 3,\n",
    "        'dropout': 0.3\n",
    "    },\n",
    "    'phonemes': PHONEMES,\n",
    "    'muscle_sensors': MUSCLE_SENSORS,\n",
    "    'scaler_mean': scaler.mean_,\n",
    "    'scaler_scale': scaler.scale_\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_name': 'TemporalCNN_EMG_Phoneme',\n",
    "    'version': '1.0',\n",
    "    'training_accuracy': float(best_accuracy),\n",
    "    'num_sensors': NUM_SENSORS,\n",
    "    'num_phonemes': NUM_PHONEMES,\n",
    "    'phonemes': PHONEMES,\n",
    "    'muscle_sensors': MUSCLE_SENSORS,\n",
    "    'created_date': '2026-02-10'\n",
    "}\n",
    "\n",
    "with open('emg_encoder_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"Metadata saved to emg_encoder_metadata.json\")\n",
    "\n",
    "\n",
    "# Function to load model for later use\n",
    "def load_emg_encoder(model_path='emg_encoder_model.pth', device='cpu'):\n",
    "    \"\"\"Load trained EMG encoder model\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    config = checkpoint['model_config']\n",
    "    model = TemporalCNN(\n",
    "        num_sensors=config['num_sensors'],\n",
    "        num_phonemes=config['num_phonemes'],\n",
    "        num_channels=config['num_channels'],\n",
    "        kernel_size=config['kernel_size'],\n",
    "        dropout=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Recreate scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.mean_ = checkpoint['scaler_mean']\n",
    "    scaler.scale_ = checkpoint['scaler_scale']\n",
    "    \n",
    "    return model, scaler, checkpoint['phonemes']\n",
    "\n",
    "\n",
    "print(\"\\n✓ Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c6089",
   "metadata": {},
   "source": [
    "## 9. Integration with MyoWare Sensors (Arduino/Serial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0897379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyoWareEMGReader:\n",
    "    \"\"\"\n",
    "    Interface for reading EMG data from MyoWare sensors via Serial/Arduino\n",
    "    \"\"\"\n",
    "    def __init__(self, port='/dev/ttyUSB0', baudrate=9600, num_sensors=NUM_SENSORS, buffer_size=100):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            port: Serial port (e.g., '/dev/ttyUSB0' on Linux/Mac, 'COM3' on Windows)\n",
    "            baudrate: Serial communication speed\n",
    "            num_sensors: Number of MyoWare sensors connected\n",
    "            buffer_size: Window size for EMG sequences\n",
    "        \"\"\"\n",
    "        self.port = port\n",
    "        self.baudrate = baudrate\n",
    "        self.num_sensors = num_sensors\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer = np.zeros((num_sensors, buffer_size))\n",
    "        self.read_index = 0\n",
    "        \n",
    "        try:\n",
    "            import serial\n",
    "            self.serial_connection = serial.Serial(port, baudrate, timeout=1)\n",
    "            print(f\"Connected to {port} at {baudrate} baud\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not connect to serial port: {e}\")\n",
    "            print(\"Running in simulation mode\")\n",
    "            self.serial_connection = None\n",
    "    \n",
    "    def read_sample(self):\n",
    "        \"\"\"Read one sample from all sensors\"\"\"\n",
    "        if self.serial_connection:\n",
    "            try:\n",
    "                line = self.serial_connection.readline().decode('utf-8').strip()\n",
    "                # Expected format: \"sensor0,sensor1,sensor2,...\"\n",
    "                values = [float(x) for x in line.split(',')]\n",
    "                if len(values) == self.num_sensors:\n",
    "                    return np.array(values)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Simulation mode: return random values\n",
    "        return np.random.rand(self.num_sensors) * 100\n",
    "    \n",
    "    def get_sequence(self):\n",
    "        \"\"\"\n",
    "        Get current buffer as EMG sequence\n",
    "        Returns shape: (num_sensors, buffer_size)\n",
    "        \"\"\"\n",
    "        return self.buffer.copy()\n",
    "    \n",
    "    def update(self):\n",
    "        \"\"\"Read new sample and update buffer\"\"\"\n",
    "        sample = self.read_sample()\n",
    "        self.buffer[:, self.read_index] = sample\n",
    "        self.read_index = (self.read_index + 1) % self.buffer_size\n",
    "        return sample\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close serial connection\"\"\"\n",
    "        if self.serial_connection:\n",
    "            self.serial_connection.close()\n",
    "\n",
    "\n",
    "# Example: Real-time EMG to phoneme streaming\n",
    "print(\"Example Real-time EMG Processing Code:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\"\"\n",
    "# Initialize reader\n",
    "emg_reader = MyoWareEMGReader(\n",
    "    port='/dev/ttyUSB0',  # Change to your Arduino port\n",
    "    num_sensors=7,\n",
    "    buffer_size=100\n",
    ")\n",
    "\n",
    "# Initialize encoder\n",
    "encoder = EMGEncoder(model, scaler, device=device)\n",
    "\n",
    "# Real-time loop\n",
    "try:\n",
    "    while True:\n",
    "        # Read new EMG sample\n",
    "        emg_reader.update()\n",
    "        \n",
    "        # Get current sequence\n",
    "        emg_sequence = emg_reader.get_sequence()\n",
    "        \n",
    "        # Predict phoneme\n",
    "        phoneme, confidence, _ = encoder.predict_phoneme(emg_sequence)\n",
    "        \n",
    "        # Only output if confidence is high\n",
    "        if confidence > 0.7:\n",
    "            print(f\"Predicted: {phoneme} (confidence: {confidence:.2f})\")\n",
    "        \n",
    "        time.sleep(0.01)  # 10ms - adjust based on your sampling rate\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    emg_reader.close()\n",
    "    print(\"Stopped\")\n",
    "\"\"\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b8b8a",
   "metadata": {},
   "source": [
    "## 10. Performance Analysis & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions on test set\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_emg, batch_labels in test_loader:\n",
    "        batch_emg = batch_emg.to(device)\n",
    "        outputs = model(batch_emg)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(batch_labels.numpy())\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Classification Report\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(all_labels, all_predictions, target_names=PHONEMES))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Plot confusion matrix (subset for clarity - first 10 phonemes)\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=PHONEMES, yticklabels=PHONEMES,\n",
    "            cbar_kws={'label': 'Count'}, ax=ax)\n",
    "ax.set_xlabel('Predicted Phoneme')\n",
    "ax.set_ylabel('True Phoneme')\n",
    "ax.set_title('Confusion Matrix - EMG to Phoneme Mapping')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Per-phoneme accuracy\n",
    "print(\"\\nPer-Phoneme Accuracy:\")\n",
    "print(\"-\" * 40)\n",
    "for i, phoneme in enumerate(PHONEMES):\n",
    "    mask = all_labels == i\n",
    "    if mask.sum() > 0:\n",
    "        acc = (all_predictions[mask] == i).sum() / mask.sum()\n",
    "        print(f\"{phoneme:6s}: {acc:.4f} ({mask.sum()} samples)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beyond-eye-gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
